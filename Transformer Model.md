
# About

It is a [[Deep Learning]] Architecture developed by [[Google]]
Used in [[Generative Pre-trained Transformer]]

Created by Google
- [Attention is All You Need - Wiki](https://en.wikipedia.org/wiki/Attention_Is_All_You_Need) 
- [[Google - Attention is All you need.pdf]]

It uses parallelism to speed up training.

# References

- [Wiki Page about Transformer](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture))